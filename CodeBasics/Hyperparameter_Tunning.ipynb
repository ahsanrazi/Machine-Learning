{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tunning Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Example: We are classifying the Iris dataset based on the sepal. petal width and length to predict what type of\n",
    "# flower it is. First question is which model should I choose there are So many models to choose from.\n",
    "\n",
    "# For Instance we choose the SVM model now we have to choose hyperparameters there are so many values to choose from.\n",
    "\n",
    "# The process of choosing the Optimal Parameters is called Hyperparameter Tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what the data contain\n",
    "\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "47                4.6               3.2                1.4               0.2   \n",
       "48                5.3               3.7                1.5               0.2   \n",
       "49                5.0               3.3                1.4               0.2   \n",
       "50                7.0               3.2                4.7               1.4   \n",
       "51                6.4               3.2                4.5               1.5   \n",
       "\n",
       "        flower  \n",
       "47      setosa  \n",
       "48      setosa  \n",
       "49      setosa  \n",
       "50  versicolor  \n",
       "51  versicolor  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the dataframe \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# Adding the flower coloumn\n",
    "df['flower'] = iris['target']\n",
    "df['flower'] = df['flower'].apply(lambda x: iris['target_names'][x])\n",
    "df[47:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Testing the SVM Model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel = 'rbf', C = 30, gamma = 'auto')\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we use the train-test split method and every time we run the train-test split method the distribution\n",
    "# in the x_train and x_test changes and it change the score of the model.\n",
    "# We cannot rely on this method because the score is changing based on the samples.\n",
    "\n",
    "# To deal with this problem we have to use the K-Folds cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K-Folds Cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score with (kernel = 'linear', C = 10, gamma = 'auto')\n",
    "\n",
    "cross_val_score(SVC(kernel = 'linear', C = 10, gamma = 'auto'), iris['data'], iris['target'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score with (kernel = 'rbf', C = 10, gamma = 'auto')\n",
    "\n",
    "cross_val_score(SVC(kernel = 'rbf', C = 10, gamma = 'auto'), iris['data'], iris['target'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score with (kernel = 'rbf', C = 20, gamma = 'auto')\n",
    "\n",
    "cross_val_score(SVC(kernel = 'rbf', C = 20, gamma = 'auto'), iris['data'], iris['target'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we use SVM model using different parameter combinations for each of the combinations we can get the scores\n",
    "# we can take the average of these and find the average score and based on this we can find the optimal values\n",
    "# for the parameters.\n",
    "\n",
    "# But this method is very manual and repetitive there are so many values we can supply as a combinations of paramaters\n",
    "# and everytime we have to wirte the code with different combinations. What is the solution of this?\n",
    "\n",
    "# One approach is use the for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': 0.9800000000000001,\n",
       " 'rbf_10': 0.9800000000000001,\n",
       " 'rbf_20': 0.9666666666666668,\n",
       " 'linear_1': 0.9800000000000001,\n",
       " 'linear_10': 0.9733333333333334,\n",
       " 'linear_20': 0.9666666666666666}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the for loop\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "kernels = ['rbf', 'linear']\n",
    "C = [1,10,20]\n",
    "avg_scores = {}\n",
    "\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(SVC(kernel=kval, C=cval, gamma='auto'), iris['data'], iris['target'], cv=5)\n",
    "        avg_scores[kval+'_'+str(cval)] = np.average(cv_scores)\n",
    "        \n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using the above apporach we can find the optimal scores using the Hyperparameter tunning.\n",
    "\n",
    "# This approach also has some issues which is if we have four parameters then we have to run four loops and there are\n",
    "# too many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The solutions of all the above problems the sklearn provide API called GridSEarchCV which will do the exact same\n",
    "# thing which we do above. (Hyperparameter tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00280781, 0.00119524, 0.00204773, 0.00153871, 0.00119686,\n",
       "        0.00091052]),\n",
       " 'std_fit_time': array([0.00075102, 0.00039659, 0.00043808, 0.00109836, 0.00039995,\n",
       "        0.00137738]),\n",
       " 'mean_score_time': array([0.00222363, 0.00059857, 0.00160675, 0.00099235, 0.00065169,\n",
       "        0.00366392]),\n",
       " 'std_score_time': array([8.66866788e-04, 4.88736259e-04, 4.87678741e-04, 1.01616672e-05,\n",
       "        5.40770205e-04, 6.34053148e-03]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 20, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'kernel': 'linear'}],\n",
       " 'split0_test_score': array([0.96666667, 0.96666667, 0.96666667, 1.        , 0.96666667,\n",
       "        1.        ]),\n",
       " 'split1_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.9       , 0.9       ,\n",
       "        0.9       ]),\n",
       " 'split3_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
       "        0.93333333]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.97333333, 0.96666667,\n",
       "        0.96666667]),\n",
       " 'std_test_score': array([0.01632993, 0.01632993, 0.01632993, 0.03887301, 0.03651484,\n",
       "        0.0421637 ]),\n",
       " 'rank_test_score': array([1, 1, 1, 4, 5, 6])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GridSearchCv\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(SVC(gamma='auto'),{\n",
    "    'C' : [1,10,20],\n",
    "    'kernel' : ['rbf', 'linear']\n",
    "}, cv = 5, return_train_score=False)\n",
    "\n",
    "clf.fit(iris['data'], iris['target'])\n",
    "clf.cv_results_\n",
    "\n",
    "# GridSearchCV(model, parameter grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.036515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.002808      0.000751         0.002224        0.000867       1   \n",
       "1       0.001195      0.000397         0.000599        0.000489       1   \n",
       "2       0.002048      0.000438         0.001607        0.000488      10   \n",
       "3       0.001539      0.001098         0.000992        0.000010      10   \n",
       "4       0.001197      0.000400         0.000652        0.000541      20   \n",
       "5       0.000911      0.001377         0.003664        0.006341      20   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0          rbf      {'C': 1, 'kernel': 'rbf'}           0.966667   \n",
       "1       linear   {'C': 1, 'kernel': 'linear'}           0.966667   \n",
       "2          rbf     {'C': 10, 'kernel': 'rbf'}           0.966667   \n",
       "3       linear  {'C': 10, 'kernel': 'linear'}           1.000000   \n",
       "4          rbf     {'C': 20, 'kernel': 'rbf'}           0.966667   \n",
       "5       linear  {'C': 20, 'kernel': 'linear'}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                1.0           0.966667           0.966667                1.0   \n",
       "1                1.0           0.966667           0.966667                1.0   \n",
       "2                1.0           0.966667           0.966667                1.0   \n",
       "3                1.0           0.900000           0.966667                1.0   \n",
       "4                1.0           0.900000           0.966667                1.0   \n",
       "5                1.0           0.900000           0.933333                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.980000        0.016330                1  \n",
       "1         0.980000        0.016330                1  \n",
       "2         0.980000        0.016330                1  \n",
       "3         0.973333        0.038873                4  \n",
       "4         0.966667        0.036515                5  \n",
       "5         0.966667        0.042164                6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The GridSearchCV results are not easy to view but sklearn provide the way we can download the results in the dataframe\n",
    "\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0       1          rbf         0.980000\n",
       "1       1       linear         0.980000\n",
       "2      10          rbf         0.980000\n",
       "3      10       linear         0.973333\n",
       "4      20          rbf         0.966667\n",
       "5      20       linear         0.966667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing only relevant features\n",
    "\n",
    "df[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_routed_params_for_fit',\n",
       " '_get_scorers',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_select_best_index',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the properties of GridSearchCV classifier\n",
    "\n",
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the best score\n",
    "\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the best parameters\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one issue with GridSearchCV is the computation cost there might be a dataset which consist of million of rows\n",
    "# and also we have number of parameters.\n",
    "\n",
    "# To tackle with the computation problem the sklearn comes up with RandomizedSearchCV\n",
    "# RandomizedSearchCv will not try thr every combination and permutation of the parameters but it will try the random \n",
    "# combination of the parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      20          rbf         0.966667\n",
       "1      20       linear         0.966667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RandomizedSearchCv\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rs = RandomizedSearchCV(SVC(gamma='auto'), {\n",
    "    'C' : [1,10,20],\n",
    "    'kernel' : ['rbf', 'linear']\n",
    "}, cv=5, return_train_score=False, n_iter=2)\n",
    "\n",
    "rs.fit(iris['data'], iris['target'])\n",
    "pd.DataFrame(rs.cv_results_)[['param_C', 'param_kernel', 'mean_test_score']]\n",
    "\n",
    "# n_iter = 2  -> It defines the number of different sets of hyperparameters to try during the random search.\n",
    "# cv = 5      -> This refers to the number of folds in cross-validation.\n",
    "\n",
    "# Everytime we run it, it will change the parameters.\n",
    "\n",
    "# This work  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Best Model and Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Models\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Parameter Grid\n",
    "\n",
    "model_params = {\n",
    "    'svm' : {\n",
    "        'model' : svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C' : [1,10,20],\n",
    "            'kernel' : ['rbf', 'linear']\n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model' : LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params' : {\n",
    "            'C' : [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop\n",
    "\n",
    "scores = []\n",
    " \n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(iris['data'], iris['target'])\n",
    "    scores.append({\n",
    "        'model' : model_name,\n",
    "        'best_score' : clf.best_score_ ,\n",
    "        'best_params' : clf.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                best_params\n",
       "0                  svm    0.980000  {'C': 1, 'kernel': 'rbf'}\n",
       "1        random_forest    0.960000        {'n_estimators': 5}\n",
       "2  logistic_regression    0.966667                   {'C': 5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
